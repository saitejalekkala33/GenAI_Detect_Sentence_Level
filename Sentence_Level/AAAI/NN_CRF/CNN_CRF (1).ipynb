{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86097caa-08c7-4126-a964-fb1b7814c2b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /root/test/lib/python3.12/site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in /root/test/lib/python3.12/site-packages (0.21.0)\n",
      "Requirement already satisfied: torchaudio in /root/test/lib/python3.12/site-packages (2.6.0)\n",
      "Requirement already satisfied: transformers in /root/test/lib/python3.12/site-packages (4.50.0)\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: pandas in /root/test/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: scikit-learn in /root/test/lib/python3.12/site-packages (1.6.1)\n",
      "Requirement already satisfied: pytorch-crf in /root/test/lib/python3.12/site-packages (0.7.2)\n",
      "Requirement already satisfied: numpy in /root/test/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: filelock in /root/test/lib/python3.12/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /root/test/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /root/test/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /root/test/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /root/test/lib/python3.12/site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /root/test/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /root/test/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /root/test/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /root/test/lib/python3.12/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /root/test/lib/python3.12/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /root/test/lib/python3.12/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /root/test/lib/python3.12/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /root/test/lib/python3.12/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /root/test/lib/python3.12/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /root/test/lib/python3.12/site-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /root/test/lib/python3.12/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /root/test/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /root/test/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /root/test/lib/python3.12/site-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: setuptools in /root/test/lib/python3.12/site-packages (from torch) (77.0.3)\n",
      "Requirement already satisfied: sympy==1.13.1 in /root/test/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /root/test/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /root/test/lib/python3.12/site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /root/test/lib/python3.12/site-packages (from transformers) (0.29.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/test/lib/python3.12/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /root/test/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /root/test/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /root/test/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /root/test/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /root/test/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /root/test/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Collecting click (from nltk)\n",
      "  Downloading click-8.2.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: joblib in /root/test/lib/python3.12/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/test/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/test/lib/python3.12/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /root/test/lib/python3.12/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /root/test/lib/python3.12/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /root/test/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in /root/test/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/test/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/test/lib/python3.12/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/test/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/test/lib/python3.12/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/test/lib/python3.12/site-packages (from requests->transformers) (2025.1.31)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading click-8.2.0-py3-none-any.whl (102 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: click, nltk\n",
      "Successfully installed click-8.2.0 nltk-3.9.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio transformers nltk pandas scikit-learn pytorch-crf numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13e33278-35f7-41a0-9192-507b9c70918d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchcrf import CRF\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef, cohen_kappa_score\n",
    "import ast\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a37a249-d50f-4948-b631-512055bfdd48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"transformers.convert_slow_tokenizer\")\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "389bfba2-d81b-401f-bbc8-844f3dee106b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_boundaries(df):\n",
    "    def adjust_boundaries(row):\n",
    "        text = str(row['hybrid_text'])\n",
    "        sentences = sent_tokenize(text)\n",
    "        num_sentences = len(sentences)\n",
    "        boundaries = row['boundary_ix']\n",
    "        if isinstance(boundaries, str):\n",
    "            try:\n",
    "                boundaries = ast.literal_eval(boundaries)\n",
    "            except (ValueError, SyntaxError):\n",
    "                boundaries = [0]\n",
    "        if not isinstance(boundaries, list):\n",
    "            boundaries = [boundaries]\n",
    "        boundaries = [min(int(b), num_sentences-1) for b in boundaries]\n",
    "        return boundaries\n",
    "\n",
    "    df['boundary_ix'] = df.apply(adjust_boundaries, axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d530f92c-0488-4728-a81f-3e00883dfeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixedTextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, author_seqs, tokenizer):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.author_seqs = author_seqs\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        author_seq = self.author_seqs[idx]\n",
    "        boundaries = self.labels[idx]\n",
    "        if not isinstance(boundaries, list):\n",
    "            boundaries = [boundaries]\n",
    "        boundaries = [int(b) for b in boundaries]\n",
    "        sentences = sent_tokenize(text)\n",
    "        word_labels = []\n",
    "        words = []\n",
    "        for sent_idx, sent in enumerate(sentences):\n",
    "            current_words = word_tokenize(sent)\n",
    "            words.extend(current_words)\n",
    "            label = self._get_label_for_sentence(sent_idx, author_seq, boundaries)\n",
    "            word_labels.extend([label] * len(current_words))\n",
    "        input_ids = []\n",
    "        attention_mask = []\n",
    "        token_labels = []\n",
    "        for word, label in zip(words, word_labels):\n",
    "            encoded_word = self.tokenizer(\n",
    "                word,\n",
    "                add_special_tokens=False,\n",
    "                return_attention_mask=True,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            word_ids = encoded_word[\"input_ids\"].squeeze()\n",
    "            word_ids = [word_ids.item()] if word_ids.dim() == 0 else word_ids.tolist()\n",
    "            input_ids.extend(word_ids)\n",
    "            attention_mask.extend([1] * len(word_ids))\n",
    "            token_labels.extend([label] * len(word_ids))\n",
    "        input_ids = [self.tokenizer.cls_token_id] + input_ids + [self.tokenizer.sep_token_id]\n",
    "        attention_mask = [1] + attention_mask + [1]\n",
    "        token_labels = [-100] + token_labels + [-100]\n",
    "        if any(l not in [-100, 0, 1] for l in token_labels):\n",
    "            print(f\"Invalid labels at index {idx}: {token_labels}\")\n",
    "        return {\n",
    "            \"input_ids\": torch.tensor(input_ids, dtype=torch.long),\n",
    "            \"attention_mask\": torch.tensor(attention_mask, dtype=torch.long),\n",
    "            \"labels\": torch.tensor(token_labels, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "    def _get_label_for_sentence(self, sent_idx, author_seq, boundaries):\n",
    "        if author_seq == 'M_H':\n",
    "            return 1 if sent_idx < boundaries[0] else 0\n",
    "        elif author_seq == 'H_M':\n",
    "            return 0 if sent_idx < boundaries[0] else 1\n",
    "        elif author_seq == 'H_M_H':\n",
    "            if sent_idx < boundaries[0]:\n",
    "                return 0\n",
    "            elif sent_idx < boundaries[1]:\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "        elif author_seq == 'M_H_M':\n",
    "            if sent_idx < boundaries[0]:\n",
    "                return 1\n",
    "            elif sent_idx < boundaries[1]:\n",
    "                return 0\n",
    "            else:\n",
    "                return 1\n",
    "        elif author_seq == 'H_M_H_M':\n",
    "            if sent_idx < boundaries[0]:\n",
    "                return 0\n",
    "            elif sent_idx < boundaries[1]:\n",
    "                return 1\n",
    "            elif sent_idx < boundaries[2]:\n",
    "                return 0\n",
    "            else:\n",
    "                return 1\n",
    "        elif author_seq == 'M_H_M_H':\n",
    "            if sent_idx < boundaries[0]:\n",
    "                return 1\n",
    "            elif sent_idx < boundaries[1]:\n",
    "                return 0\n",
    "            elif sent_idx < boundaries[2]:\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown author_seq: {author_seq}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc1f90e1-7cac-46d3-8e18-3ab194e896c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNCRFTagger(nn.Module):\n",
    "    def __init__(self, input_dim, num_labels, embedding_dim=768, num_filters=100, kernel_size=3, dropout=0.3):\n",
    "        super(CNNCRFTagger, self).__init__()\n",
    "        self.num_labels = num_labels\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.embed_dropout = nn.Dropout(dropout)\n",
    "        self.conv = nn.Conv1d(in_channels=embedding_dim, out_channels=num_filters, kernel_size=kernel_size, padding=kernel_size//2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.hidden2tag = nn.Linear(num_filters, num_labels)\n",
    "        self.crf = CRF(num_labels, batch_first=True)\n",
    "        for name, param in self.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                if len(param.shape) > 1:\n",
    "                    nn.init.xavier_uniform_(param)\n",
    "                else:\n",
    "                    nn.init.normal_(param, mean=0, std=0.01)\n",
    "            elif 'bias' in name:\n",
    "                nn.init.constant_(param, 0)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        if input_ids.numel() == 0:\n",
    "            raise ValueError(\"Input tensor is empty.\")\n",
    "        embedded = self.embedding(input_ids)\n",
    "        embedded = self.embed_dropout(embedded).permute(0, 2, 1)\n",
    "        conv_out = self.relu(self.conv(embedded)).permute(0, 2, 1)\n",
    "        logits = self.hidden2tag(conv_out)\n",
    "        if labels is not None:\n",
    "            mask = attention_mask.bool()\n",
    "            crf_labels = labels.clone()\n",
    "            crf_labels[crf_labels == -100] = 0\n",
    "            loss = -self.crf(logits, crf_labels, mask=mask, reduction='mean')\n",
    "            return loss\n",
    "        else:\n",
    "            mask = attention_mask.bool()\n",
    "            predictions = self.crf.decode(logits, mask=mask)\n",
    "            return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ee58206-5190-448e-8da2-c5cca888a54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, data_loader, optimizer, scheduler, device, clip_value=1.0):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in data_loader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = model(input_ids, attention_mask, labels)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=clip_value)\n",
    "        optimizer.step()\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "def evaluate_model(model, data_loader, device):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            mask = attention_mask.bool()\n",
    "            predictions = model(input_ids, attention_mask)\n",
    "            for pred_seq, label_seq, mask_seq in zip(predictions, labels, attention_mask):\n",
    "                true_len = mask_seq.sum().item()\n",
    "                valid_label = label_seq[:true_len].cpu().numpy()\n",
    "                non_special_label_indices = (label_seq[:true_len] != -100).nonzero(as_tuple=True)[0]\n",
    "                if non_special_label_indices.numel() == 0:\n",
    "                    continue\n",
    "                pred_seq_np = np.array(pred_seq)\n",
    "                valid_pred = pred_seq_np[non_special_label_indices.cpu().numpy()]\n",
    "                valid_label = label_seq[non_special_label_indices].cpu().numpy()\n",
    "                all_predictions.extend(valid_pred)\n",
    "                all_labels.extend(valid_label)\n",
    "    all_predictions = np.array(all_predictions)\n",
    "    all_labels = np.array(all_labels)\n",
    "    if len(all_labels) == 0:\n",
    "        print(\"Warning: No valid tokens to evaluate. Returning default metrics.\")\n",
    "        return 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "    absolute_errors = np.abs(all_predictions - all_labels)\n",
    "    mae = np.mean(absolute_errors)\n",
    "    std_dev = np.std(absolute_errors)\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    precision = precision_score(all_labels, all_predictions, average='weighted', zero_division=0)\n",
    "    recall = recall_score(all_labels, all_predictions, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_predictions, average='weighted', zero_division=0)\n",
    "    mcc = matthews_corrcoef(all_labels, all_predictions)\n",
    "    kappa = cohen_kappa_score(all_labels, all_predictions)\n",
    "    return accuracy, precision, recall, f1, mcc, mae, std_dev, kappa\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    max_len = max(len(item[\"input_ids\"]) for item in batch)\n",
    "    input_ids_batch = []\n",
    "    attention_mask_batch = []\n",
    "    labels_batch = []\n",
    "    for item in batch:\n",
    "        seq_len = len(item[\"input_ids\"])\n",
    "        pad_len = max_len - seq_len\n",
    "        input_ids_batch.append(torch.cat([item[\"input_ids\"], torch.tensor([0] * pad_len, dtype=torch.long)]))\n",
    "        attention_mask_batch.append(torch.cat([item[\"attention_mask\"], torch.tensor([0] * pad_len, dtype=torch.long)]))\n",
    "        labels_batch.append(torch.cat([item[\"labels\"], torch.tensor([-100] * pad_len, dtype=torch.long)]))\n",
    "    return {\n",
    "        \"input_ids\": torch.stack(input_ids_batch),\n",
    "        \"attention_mask\": torch.stack(attention_mask_batch),\n",
    "        \"labels\": torch.stack(labels_batch)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f88c517-76d1-4bb7-837c-e26a5ad04204",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'batch_size': 16,\n",
    "    'learning_rate': 1e-3,\n",
    "    'hidden_dim': 512,\n",
    "    'embedding_dim': 768,\n",
    "    'num_layers': 2,\n",
    "    'dropout': 0.3,\n",
    "    'epochs': 5,\n",
    "    'weight_decay': 0.01,\n",
    "    'gradient_clip': 1.0\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "672b6a8d-86f5-4cfe-87f9-919808264541",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('aaai_train.csv')\n",
    "dev_df = pd.read_csv('aaai_valid.csv')\n",
    "test_df = pd.read_csv('aaai_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6dd7751-2398-4ca1-a99d-027ad8d74cdc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essayset</th>\n",
       "      <th>essay</th>\n",
       "      <th>score1</th>\n",
       "      <th>score2</th>\n",
       "      <th>score</th>\n",
       "      <th>ratio</th>\n",
       "      <th>train_ix</th>\n",
       "      <th>sent_and_label</th>\n",
       "      <th>hybrid_text</th>\n",
       "      <th>boundary_ix</th>\n",
       "      <th>boundary_num</th>\n",
       "      <th>author_seq</th>\n",
       "      <th>human_part</th>\n",
       "      <th>machine_part</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4082</td>\n",
       "      <td>2</td>\n",
       "      <td>Dear sir or mam, Have you or someone in your f...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.008306</td>\n",
       "      <td>train</td>\n",
       "      <td>[('Dear sir or mam, Have you or someone in you...</td>\n",
       "      <td>Dear sir or mam, Have you or someone in your f...</td>\n",
       "      <td>[14]</td>\n",
       "      <td>1</td>\n",
       "      <td>H_M</td>\n",
       "      <td>Dear sir or mam, Have you or someone in your f...</td>\n",
       "      <td>\"All of us can think of a book that we hope no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17830</td>\n",
       "      <td>6</td>\n",
       "      <td>The obstacles that the builders faced in attem...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.597949</td>\n",
       "      <td>train</td>\n",
       "      <td>[('The obstacles that the builders faced in at...</td>\n",
       "      <td>The obstacles that the builders faced in attem...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>1</td>\n",
       "      <td>H_M</td>\n",
       "      <td>The obstacles that the builders faced in attem...</td>\n",
       "      <td>A dirigible moored at the top of the building ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16158</td>\n",
       "      <td>6</td>\n",
       "      <td>The builders of the Empire State Building face...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.374359</td>\n",
       "      <td>train</td>\n",
       "      <td>[('The builders of the Empire State Building f...</td>\n",
       "      <td>The builders of the Empire State Building face...</td>\n",
       "      <td>[2]</td>\n",
       "      <td>1</td>\n",
       "      <td>H_M</td>\n",
       "      <td>The builders of the Empire State Building face...</td>\n",
       "      <td>A mooring mast had to be added to the top of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16670</td>\n",
       "      <td>6</td>\n",
       "      <td>The builders of the Empire State Building face...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.473846</td>\n",
       "      <td>train</td>\n",
       "      <td>[('The builders of the Empire State Building f...</td>\n",
       "      <td>The builders of the Empire State Building face...</td>\n",
       "      <td>[2]</td>\n",
       "      <td>1</td>\n",
       "      <td>H_M</td>\n",
       "      <td>The builders of the Empire State Building face...</td>\n",
       "      <td>A thousand-foot dirigible moored at the top of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17803</td>\n",
       "      <td>6</td>\n",
       "      <td>The builders of the Empire State Building face...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.265641</td>\n",
       "      <td>train</td>\n",
       "      <td>[('The builders of the Empire State Building f...</td>\n",
       "      <td>The builders of the Empire State Building face...</td>\n",
       "      <td>[2]</td>\n",
       "      <td>1</td>\n",
       "      <td>H_M</td>\n",
       "      <td>The builders of the Empire State Building face...</td>\n",
       "      <td>A thousand-foot dirigible moored at the top of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12044</th>\n",
       "      <td>21608</td>\n",
       "      <td>8</td>\n",
       "      <td>Hey guys, I have a story to tell you that happ...</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>train</td>\n",
       "      <td>[('Hey guys, I have a story to tell you that h...</td>\n",
       "      <td>Hey guys, I have a story to tell you that happ...</td>\n",
       "      <td>[21, 24, 28]</td>\n",
       "      <td>3</td>\n",
       "      <td>M_H_M_H</td>\n",
       "      <td>Imagine the world with just laughter, how life...</td>\n",
       "      <td>Hey guys, I have a story to tell you that happ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12045</th>\n",
       "      <td>21533</td>\n",
       "      <td>8</td>\n",
       "      <td>Hey guys, have you ever had a moment when you ...</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>35</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>train</td>\n",
       "      <td>[(\"Hey guys, have you ever had a moment when y...</td>\n",
       "      <td>Hey guys, have you ever had a moment when you ...</td>\n",
       "      <td>[4, 5, 7]</td>\n",
       "      <td>3</td>\n",
       "      <td>M_H_M_H</td>\n",
       "      <td>Before i could do all that the wash had starte...</td>\n",
       "      <td>Hey guys, have you ever had a moment when you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12046</th>\n",
       "      <td>22130</td>\n",
       "      <td>8</td>\n",
       "      <td>I remember this one time when I was playing ba...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>train</td>\n",
       "      <td>[('I remember this one time when I was playing...</td>\n",
       "      <td>I remember this one time when I was playing ba...</td>\n",
       "      <td>[5, 7, 15]</td>\n",
       "      <td>3</td>\n",
       "      <td>M_H_M_H</td>\n",
       "      <td>One kid on the team had a different outlook on...</td>\n",
       "      <td>I remember this one time when I was playing ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12047</th>\n",
       "      <td>21711</td>\n",
       "      <td>8</td>\n",
       "      <td>Hey there! Today, I am going to tell you a tru...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>train</td>\n",
       "      <td>[('Hey there!', 'machine'), ('Today, I am goin...</td>\n",
       "      <td>Hey there! Today, I am going to tell you a tru...</td>\n",
       "      <td>[6, 9, 22]</td>\n",
       "      <td>3</td>\n",
       "      <td>M_H_M_H</td>\n",
       "      <td>I however was determined to find that somethin...</td>\n",
       "      <td>Hey there! Today, I am going to tell you a tru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12048</th>\n",
       "      <td>21244</td>\n",
       "      <td>8</td>\n",
       "      <td>Hey guys, I have a story to share with you abo...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>train</td>\n",
       "      <td>[('Hey guys, I have a story to share with you ...</td>\n",
       "      <td>Hey guys, I have a story to share with you abo...</td>\n",
       "      <td>[8, 15, 22]</td>\n",
       "      <td>3</td>\n",
       "      <td>M_H_M_H</td>\n",
       "      <td>about ten seconds later we heard banging on th...</td>\n",
       "      <td>Hey guys, I have a story to share with you abo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12049 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       essay_id  essayset                                              essay  \\\n",
       "0          4082         2  Dear sir or mam, Have you or someone in your f...   \n",
       "1         17830         6  The obstacles that the builders faced in attem...   \n",
       "2         16158         6  The builders of the Empire State Building face...   \n",
       "3         16670         6  The builders of the Empire State Building face...   \n",
       "4         17803         6  The builders of the Empire State Building face...   \n",
       "...         ...       ...                                                ...   \n",
       "12044     21608         8  Hey guys, I have a story to tell you that happ...   \n",
       "12045     21533         8  Hey guys, have you ever had a moment when you ...   \n",
       "12046     22130         8  I remember this one time when I was playing ba...   \n",
       "12047     21711         8  Hey there! Today, I am going to tell you a tru...   \n",
       "12048     21244         8  Hey guys, I have a story to share with you abo...   \n",
       "\n",
       "       score1  score2  score     ratio train_ix  \\\n",
       "0           4       3      4  0.008306    train   \n",
       "1          -1      -1     -1  0.597949    train   \n",
       "2           3       3      3  0.374359    train   \n",
       "3          -1      -1     -1  0.473846    train   \n",
       "4          -1      -1     -1  0.265641    train   \n",
       "...       ...     ...    ...       ...      ...   \n",
       "12044      20      20     40  0.083333    train   \n",
       "12045      17      18     35  0.533333    train   \n",
       "12046      -1      -1     -1  0.150000    train   \n",
       "12047      -1      -1     -1  0.600000    train   \n",
       "12048      15      15     30  0.583333    train   \n",
       "\n",
       "                                          sent_and_label  \\\n",
       "0      [('Dear sir or mam, Have you or someone in you...   \n",
       "1      [('The obstacles that the builders faced in at...   \n",
       "2      [('The builders of the Empire State Building f...   \n",
       "3      [('The builders of the Empire State Building f...   \n",
       "4      [('The builders of the Empire State Building f...   \n",
       "...                                                  ...   \n",
       "12044  [('Hey guys, I have a story to tell you that h...   \n",
       "12045  [(\"Hey guys, have you ever had a moment when y...   \n",
       "12046  [('I remember this one time when I was playing...   \n",
       "12047  [('Hey there!', 'machine'), ('Today, I am goin...   \n",
       "12048  [('Hey guys, I have a story to share with you ...   \n",
       "\n",
       "                                             hybrid_text   boundary_ix  \\\n",
       "0      Dear sir or mam, Have you or someone in your f...          [14]   \n",
       "1      The obstacles that the builders faced in attem...           [1]   \n",
       "2      The builders of the Empire State Building face...           [2]   \n",
       "3      The builders of the Empire State Building face...           [2]   \n",
       "4      The builders of the Empire State Building face...           [2]   \n",
       "...                                                  ...           ...   \n",
       "12044  Hey guys, I have a story to tell you that happ...  [21, 24, 28]   \n",
       "12045  Hey guys, have you ever had a moment when you ...     [4, 5, 7]   \n",
       "12046  I remember this one time when I was playing ba...    [5, 7, 15]   \n",
       "12047  Hey there! Today, I am going to tell you a tru...    [6, 9, 22]   \n",
       "12048  Hey guys, I have a story to share with you abo...   [8, 15, 22]   \n",
       "\n",
       "       boundary_num author_seq  \\\n",
       "0                 1        H_M   \n",
       "1                 1        H_M   \n",
       "2                 1        H_M   \n",
       "3                 1        H_M   \n",
       "4                 1        H_M   \n",
       "...             ...        ...   \n",
       "12044             3    M_H_M_H   \n",
       "12045             3    M_H_M_H   \n",
       "12046             3    M_H_M_H   \n",
       "12047             3    M_H_M_H   \n",
       "12048             3    M_H_M_H   \n",
       "\n",
       "                                              human_part  \\\n",
       "0      Dear sir or mam, Have you or someone in your f...   \n",
       "1      The obstacles that the builders faced in attem...   \n",
       "2      The builders of the Empire State Building face...   \n",
       "3      The builders of the Empire State Building face...   \n",
       "4      The builders of the Empire State Building face...   \n",
       "...                                                  ...   \n",
       "12044  Imagine the world with just laughter, how life...   \n",
       "12045  Before i could do all that the wash had starte...   \n",
       "12046  One kid on the team had a different outlook on...   \n",
       "12047  I however was determined to find that somethin...   \n",
       "12048  about ten seconds later we heard banging on th...   \n",
       "\n",
       "                                            machine_part  \n",
       "0      \"All of us can think of a book that we hope no...  \n",
       "1      A dirigible moored at the top of the building ...  \n",
       "2      A mooring mast had to be added to the top of t...  \n",
       "3      A thousand-foot dirigible moored at the top of...  \n",
       "4      A thousand-foot dirigible moored at the top of...  \n",
       "...                                                  ...  \n",
       "12044  Hey guys, I have a story to tell you that happ...  \n",
       "12045  Hey guys, have you ever had a moment when you ...  \n",
       "12046  I remember this one time when I was playing ba...  \n",
       "12047  Hey there! Today, I am going to tell you a tru...  \n",
       "12048  Hey guys, I have a story to share with you abo...  \n",
       "\n",
       "[12049 rows x 15 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa7c4922-bae9-4f3e-85b1-c21735d31881",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = preprocess_boundaries(train_df)\n",
    "dev_df = preprocess_boundaries(dev_df)\n",
    "test_df = preprocess_boundaries(test_df)\n",
    "\n",
    "train_texts = train_df[\"hybrid_text\"].tolist()\n",
    "train_labels = train_df[\"boundary_ix\"].tolist()\n",
    "train_author_seqs = train_df[\"author_seq\"].tolist()\n",
    "dev_texts = dev_df[\"hybrid_text\"].tolist()\n",
    "dev_labels = dev_df[\"boundary_ix\"].tolist()\n",
    "dev_author_seqs = dev_df[\"author_seq\"].tolist()\n",
    "test_texts = test_df[\"hybrid_text\"].tolist()\n",
    "test_labels = test_df[\"boundary_ix\"].tolist()\n",
    "test_author_seqs = test_df[\"author_seq\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0af4aa6c-2090-4bfe-b59e-a4b73fc07480",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'microsoft/deberta-v3-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "train_dataset = MixedTextDataset(train_texts, train_labels, train_author_seqs, tokenizer)\n",
    "dev_dataset = MixedTextDataset(dev_texts, dev_labels, dev_author_seqs, tokenizer)\n",
    "test_dataset = MixedTextDataset(test_texts, test_labels, test_author_seqs, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, collate_fn=custom_collate_fn)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=config['batch_size'], shuffle=False, collate_fn=custom_collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False, collate_fn=custom_collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81745403-73c4-45b1-9f51-01991daa6f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "vocab_size = tokenizer.vocab_size\n",
    "num_labels = 2\n",
    "\n",
    "model = CNNCRFTagger(\n",
    "    vocab_size,\n",
    "    num_labels,\n",
    "    embedding_dim=config['embedding_dim'],\n",
    "    num_filters=config['hidden_dim'],\n",
    "    dropout=config['dropout']\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config['learning_rate'], weight_decay=config['weight_decay'])\n",
    "total_steps = len(train_loader) * config['epochs']\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=config['learning_rate'],\n",
    "                                               total_steps=total_steps, pct_start=0.1, anneal_strategy='cos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9cf93515-76b6-4d75-b813-f68df285d5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Training on device: cuda\n",
      "Number of training examples: 12049\n",
      "Number of validation examples: 2527\n",
      "Number of test examples: 2560\n",
      "\n",
      "Epoch 1/5\n",
      "Train Loss: 108.4797\n",
      "Validation Metrics:\n",
      "Accuracy: 0.8283\n",
      "Precision: 0.8476\n",
      "Recall: 0.8283\n",
      "F1 Score: 0.8130\n",
      "MCC: 0.6127\n",
      "Kappa: 0.5697\n",
      "MAE: 0.17±0.38\n",
      "New best model with Kappa Score: 0.5697\n",
      "\n",
      "Epoch 2/5\n",
      "Train Loss: 29.1262\n",
      "Validation Metrics:\n",
      "Accuracy: 0.9349\n",
      "Precision: 0.9346\n",
      "Recall: 0.9349\n",
      "F1 Score: 0.9346\n",
      "MCC: 0.8534\n",
      "Kappa: 0.8531\n",
      "MAE: 0.07±0.25\n",
      "New best model with Kappa Score: 0.8531\n",
      "\n",
      "Epoch 3/5\n",
      "Train Loss: 11.3757\n",
      "Validation Metrics:\n",
      "Accuracy: 0.9451\n",
      "Precision: 0.9450\n",
      "Recall: 0.9451\n",
      "F1 Score: 0.9448\n",
      "MCC: 0.8764\n",
      "Kappa: 0.8759\n",
      "MAE: 0.05±0.23\n",
      "New best model with Kappa Score: 0.8759\n",
      "\n",
      "Epoch 4/5\n",
      "Train Loss: 7.3314\n",
      "Validation Metrics:\n",
      "Accuracy: 0.9462\n",
      "Precision: 0.9461\n",
      "Recall: 0.9462\n",
      "F1 Score: 0.9458\n",
      "MCC: 0.8786\n",
      "Kappa: 0.8778\n",
      "MAE: 0.05±0.23\n",
      "New best model with Kappa Score: 0.8778\n",
      "\n",
      "Epoch 5/5\n",
      "Train Loss: 6.2064\n",
      "Validation Metrics:\n",
      "Accuracy: 0.9441\n",
      "Precision: 0.9443\n",
      "Recall: 0.9441\n",
      "F1 Score: 0.9435\n",
      "MCC: 0.8739\n",
      "Kappa: 0.8725\n",
      "MAE: 0.06±0.23\n",
      "\n",
      "Training completed!\n",
      "Best model at epoch 4 with Kappa Score: 0.8778\n",
      "\n",
      "Evaluating test data...\n",
      "\n",
      "Test Metrics:\n",
      "Accuracy: 0.9472\n",
      "Precision: 0.9472\n",
      "Recall: 0.9472\n",
      "F1 Score: 0.9469\n",
      "MCC: 0.8828\n",
      "Kappa: 0.8822\n",
      "MAE: 0.05±0.22\n"
     ]
    }
   ],
   "source": [
    "best_kappa = -float('inf')\n",
    "best_epoch = 0\n",
    "patience = 2\n",
    "patience_counter = 0\n",
    "best_model_state = None\n",
    "train_losses = []\n",
    "val_metrics = {'accuracy': [], 'precision': [], 'recall': [], 'f1': [], 'mcc': [], 'mae': [], 'std_dev': [], 'kappa': []}\n",
    "\n",
    "print(\"Starting training...\")\n",
    "print(f\"Training on device: {device}\")\n",
    "print(f\"Number of training examples: {len(train_dataset)}\")\n",
    "print(f\"Number of validation examples: {len(dev_dataset)}\")\n",
    "print(f\"Number of test examples: {len(test_dataset)}\")\n",
    "\n",
    "\n",
    "for epoch in range(config['epochs']):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{config['epochs']}\")\n",
    "    train_loss = train_model(model, train_loader, optimizer, scheduler, device, config['gradient_clip'])\n",
    "    train_losses.append(train_loss)\n",
    "    val_accuracy, val_precision, val_recall, val_f1, val_mcc, val_mae, val_std_dev, val_kappa = evaluate_model(model, dev_loader, device)\n",
    "    val_metrics['accuracy'].append(val_accuracy)\n",
    "    val_metrics['precision'].append(val_precision)\n",
    "    val_metrics['recall'].append(val_recall)\n",
    "    val_metrics['f1'].append(val_f1)\n",
    "    val_metrics['mcc'].append(val_mcc)\n",
    "    val_metrics['mae'].append(val_mae)\n",
    "    val_metrics['std_dev'].append(val_std_dev)\n",
    "    val_metrics['kappa'].append(val_kappa)\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"Validation Metrics:\")\n",
    "    print(f\"Accuracy: {val_accuracy:.4f}\")\n",
    "    print(f\"Precision: {val_precision:.4f}\")\n",
    "    print(f\"Recall: {val_recall:.4f}\")\n",
    "    print(f\"F1 Score: {val_f1:.4f}\")\n",
    "    print(f\"MCC: {val_mcc:.4f}\")\n",
    "    print(f\"Kappa: {val_kappa:.4f}\")\n",
    "    print(f\"MAE: {val_mae:.2f}±{val_std_dev:.2f}\")\n",
    "    if val_kappa > best_kappa:\n",
    "        best_kappa = val_kappa\n",
    "        best_epoch = epoch + 1\n",
    "        patience_counter = 0\n",
    "        best_model_state = {\n",
    "            'model_state_dict': {k: v.cpu() for k, v in model.state_dict().items()},\n",
    "            'epoch': epoch + 1,\n",
    "            'metrics': {\n",
    "                'kappa': val_kappa,\n",
    "                'f1': val_f1,\n",
    "                'accuracy': val_accuracy,\n",
    "                'precision': val_precision,\n",
    "                'recall': val_recall,\n",
    "                'mcc': val_mcc,\n",
    "                'mae': val_mae,\n",
    "                'std_dev': val_std_dev\n",
    "            }\n",
    "        }\n",
    "        print(f\"New best model with Kappa Score: {val_kappa:.4f}\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping triggered after {epoch + 1} epochs\")\n",
    "            break\n",
    "\n",
    "\n",
    "print(\"\\nTraining completed!\")\n",
    "print(f\"Best model at epoch {best_epoch} with Kappa Score: {best_kappa:.4f}\")\n",
    "\n",
    "if best_model_state is not None:\n",
    "    print(\"\\nEvaluating test data...\")\n",
    "    model.load_state_dict(best_model_state['model_state_dict'])\n",
    "    model.to(device)\n",
    "    test_accuracy, test_precision, test_recall, test_f1, test_mcc, test_mae, test_std_dev, test_kappa = evaluate_model(model, test_loader, device)\n",
    "    print(\"\\nTest Metrics:\")\n",
    "    print(f\"Accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"Precision: {test_precision:.4f}\")\n",
    "    print(f\"Recall: {test_recall:.4f}\")\n",
    "    print(f\"F1 Score: {test_f1:.4f}\")\n",
    "    print(f\"MCC: {test_mcc:.4f}\")\n",
    "    print(f\"Kappa: {test_kappa:.4f}\")\n",
    "    print(f\"MAE: {test_mae:.2f}±{test_std_dev:.2f}\")\n",
    "else:\n",
    "    print(\"\\nNo valid model state found. Skipping test evaluation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74aa063-1a41-456c-a9dc-2f242459adba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
